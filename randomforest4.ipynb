{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, r2_score, max_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = df[[\"koi_period\",\"koi_period_err1\",\"koi_period_err2\",\"koi_time0bk\",\"koi_time0bk_err1\",\n",
    "                     \"koi_steff_err2\",\"koi_slogg\",\"koi_slogg_err1\",\"koi_slogg_err2\",\"koi_srad\",\n",
    "                     \"koi_srad_err1\",\"koi_srad_err2\",\"ra\",\"dec\",\"koi_kepmag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(selected_features.corr(), cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['koi_disposition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (6991, 40) (6991,)\n"
     ]
    }
   ],
   "source": [
    "# create features\n",
    "X = df.drop(\"koi_disposition\", axis=1)\n",
    "feature_names = X.columns\n",
    "# create labels\n",
    "y = df[\"koi_disposition\"]\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0000\n",
      "Testing Data Score: 0.8890\n"
     ]
    }
   ],
   "source": [
    "# create a Gaussian Classifier with default n_esimators value\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# train the model\n",
    "model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train):.4f}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test data set\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.82      0.73      0.77       422\n",
      "     CONFIRMED       0.79      0.83      0.81       450\n",
      "FALSE POSITIVE       0.97      1.00      0.98       876\n",
      "\n",
      "      accuracy                           0.89      1748\n",
      "     macro avg       0.86      0.85      0.85      1748\n",
      "  weighted avg       0.89      0.89      0.89      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check performance of model with classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>CANDIDATE</th>\n",
       "      <th>CONFIRMED</th>\n",
       "      <th>FALSE POSITIVE</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CANDIDATE</th>\n",
       "      <td>309</td>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONFIRMED</th>\n",
       "      <td>65</td>\n",
       "      <td>373</td>\n",
       "      <td>12</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FALSE POSITIVE</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>872</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>377</td>\n",
       "      <td>473</td>\n",
       "      <td>898</td>\n",
       "      <td>1748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted       CANDIDATE  CONFIRMED  FALSE POSITIVE   All\n",
       "True                                                      \n",
       "CANDIDATE             309         99              14   422\n",
       "CONFIRMED              65        373              12   450\n",
       "FALSE POSITIVE          3          1             872   876\n",
       "All                   377        473             898  1748"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8890160183066361\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_imp = pd.Series(model.feature_importances_, index = feature_names).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar plot\n",
    "plt.figure(figsize=(10,12))\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of grid searching key hyperparametres for KNeighborsClassifier\n",
    "max_features = []\n",
    "\n",
    "# set range 1 to half the number of input features ie 20\n",
    "for i in range(1,20):\n",
    "    max_features.append(i)\n",
    "\n",
    "# define grid search\n",
    "param_grid = {'max_features': max_features, \n",
    "              'n_estimators': [200, 210, 220],\n",
    "              'max_depth': [20, 25, 30]\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(model, param_grid, n_jobs = -1, verbose = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': None,\n",
       " 'error_score': nan,\n",
       " 'estimator__bootstrap': True,\n",
       " 'estimator__ccp_alpha': 0.0,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__criterion': 'gini',\n",
       " 'estimator__max_depth': None,\n",
       " 'estimator__max_features': 'auto',\n",
       " 'estimator__max_leaf_nodes': None,\n",
       " 'estimator__max_samples': None,\n",
       " 'estimator__min_impurity_decrease': 0.0,\n",
       " 'estimator__min_impurity_split': None,\n",
       " 'estimator__min_samples_leaf': 1,\n",
       " 'estimator__min_samples_split': 2,\n",
       " 'estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'estimator__n_estimators': 100,\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__oob_score': False,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__verbose': 0,\n",
       " 'estimator__warm_start': False,\n",
       " 'estimator': RandomForestClassifier(),\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': {'max_features': [1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19],\n",
       "  'n_estimators': [200, 210, 220],\n",
       "  'max_depth': [20, 25, 30]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 171 candidates, totalling 855 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 41.5min\n",
      "[Parallel(n_jobs=-1)]: Done 855 out of 855 | elapsed: 45.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [20, 25, 30],\n",
       "                         'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19],\n",
       "                         'n_estimators': [200, 210, 220]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch (cross validate to determine hyper parameter values for best accuracy)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'max_features': 15, 'n_estimators': 200}\n",
      "0.9067350584708083\n",
      "RandomForestClassifier(max_depth=30, max_features=15, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0000\n",
      "Testing Data Score: 0.8947\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {grid.score(X_train_scaled, y_train):.4f}\")\n",
    "print(f\"Testing Data Score: {grid.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([  2.02159367,   2.30044699,   2.31480823,   2.57311807,\n",
      "         3.19026799,   3.59119558,   3.92131391,   4.90927038,\n",
      "         5.1284852 ,   4.86598945,   5.17695422,   5.35168948,\n",
      "         5.81046152,   6.40187936,   6.15553927,   6.73638616,\n",
      "         6.28080368,   7.82766833,   7.59867949,   7.39283004,\n",
      "         7.15486631,   7.30695505,   8.50379171,   8.41928568,\n",
      "         7.96869059,   8.4647644 ,   9.40784197,   8.47114711,\n",
      "         9.11382871,   9.8937428 ,  10.15883417,  12.59771204,\n",
      "        12.46067801,  10.79553061,  11.06381025,  12.58374939,\n",
      "        15.61963058,  12.15429792,  12.72138128,  13.84058881,\n",
      "        14.7553412 ,  14.08274045,  12.39186239,  15.45225863,\n",
      "        15.40917344,  13.30222831,  13.91758747,  16.75100489,\n",
      "        17.46203556,  16.4999651 ,  17.28476162,  18.51858315,\n",
      "        15.71377902,  17.59215598,  18.51548629,  18.91867871,\n",
      "        18.66590805,   2.36148529,   2.67005968,   3.08834062,\n",
      "         4.17942367,   6.73849578,   6.06482062,   4.66941595,\n",
      "         5.18685017,   5.00263467,   5.60402651,   6.18366313,\n",
      "         5.53519707,   6.10128217,   7.10878949,   7.61822677,\n",
      "         8.86788297,   9.19082246,   7.5926959 ,   7.4875771 ,\n",
      "         8.17234583,   8.35465741,   8.69275508,   8.5700819 ,\n",
      "         8.59441748,   8.22001877,   8.70093288,   9.10325518,\n",
      "         9.03663435,   9.8943418 ,  10.05172029,  10.25876617,\n",
      "        10.41096044,  10.69739385,  10.78874979,  11.14459805,\n",
      "        11.74299688,  11.33847985,  12.13355284,  12.61027851,\n",
      "        11.95323572,  12.55741911,  14.18626189,  13.05987644,\n",
      "        13.60781074,  14.87202988,  16.63310046,  15.48776226,\n",
      "        14.99769387,  15.49057636,  14.82395806,  15.72235618,\n",
      "        15.33778377,  15.88332543,  16.46915917,  15.91583877,\n",
      "        16.23219252,  17.07055116,   2.13289618,   2.43089962,\n",
      "         2.48276043,   3.1350162 ,   3.11806207,   3.12763605,\n",
      "         3.82257781,   3.77550373,   3.99471722,   4.34398327,\n",
      "         4.67968578,   4.84803629,   5.14105234,   5.40335097,\n",
      "         6.34543114,   6.02409034,   6.12801256,   6.58978143,\n",
      "         6.89616156, 438.64112897,   9.84434242,   8.79005947,\n",
      "         8.15670919,   9.07573104,   8.57766199,   8.48451185,\n",
      "         9.77865095,   9.09946675,   8.94248657,   9.4997963 ,\n",
      "         9.76648569,   9.88735976,  10.42292705,  10.07445598,\n",
      "        10.81767149,  11.61453691,  10.69200797,  11.60357041,\n",
      "        11.76872873,  11.56646967,  12.49159255,  12.63999872,\n",
      "        13.2421886 ,  14.02369819,  13.84477792,  14.0217051 ,\n",
      "        14.53134232,  14.7024837 ,  13.66824908,  13.69018898,\n",
      "        15.21611009,  14.45773768,  15.24563069,  16.2593205 ,\n",
      "        15.28771801,  18.73387904,  17.01298394]), 'std_fit_time': array([2.21395370e-02, 8.45943456e-02, 1.01717902e-01, 7.14277221e-02,\n",
      "       2.52831560e-01, 9.75169907e-02, 7.58850365e-02, 2.38805704e-01,\n",
      "       5.35853832e-01, 3.12064181e-01, 1.86703615e-01, 2.36837903e-01,\n",
      "       2.18128870e-01, 3.16208559e-01, 9.65432750e-02, 1.82554848e-01,\n",
      "       1.94920308e-01, 1.20049445e+00, 1.04896294e+00, 3.53692531e-01,\n",
      "       1.45880865e-01, 2.92029426e-01, 4.30165624e-01, 2.45635921e-01,\n",
      "       2.11432601e-01, 2.44825918e-01, 3.23249464e-01, 9.84958226e-02,\n",
      "       3.88291850e-01, 2.18121591e-01, 2.79202123e-01, 8.47938841e-01,\n",
      "       8.85677085e-01, 5.40882965e-01, 1.39894452e-01, 1.10019193e+00,\n",
      "       1.40360563e+00, 7.37285836e-01, 9.73726202e-01, 1.56062152e-01,\n",
      "       2.62723419e-01, 6.46754627e-01, 2.42180096e-01, 5.44865300e-01,\n",
      "       9.48486898e-01, 3.50283698e-01, 3.60124599e-01, 1.08395542e+00,\n",
      "       5.15674389e-01, 1.41484921e+00, 1.72784903e+00, 8.73524954e-01,\n",
      "       4.14583277e-01, 1.15040726e+00, 4.54355567e-01, 2.38302135e-01,\n",
      "       3.49266388e-01, 1.35213536e-01, 1.79054850e-01, 5.90848682e-02,\n",
      "       6.23629428e-01, 6.64701262e-01, 1.53068149e+00, 2.74735947e-01,\n",
      "       2.06731990e-01, 1.59401392e-01, 8.71831777e-02, 2.13969766e-01,\n",
      "       6.68512764e-02, 1.07263938e-01, 2.42617443e-01, 2.83978957e-01,\n",
      "       3.98269420e-01, 1.04905242e+00, 3.40116429e-01, 3.29257522e-01,\n",
      "       2.84310989e-01, 1.41487944e-01, 4.04464292e-01, 1.61382369e-01,\n",
      "       2.21880793e-01, 8.12446700e-02, 7.31470916e-02, 1.41627236e-01,\n",
      "       1.01960897e-01, 3.23048473e-01, 3.23763783e-01, 7.36014146e-02,\n",
      "       2.85369023e-01, 1.44767924e-01, 2.22258737e-01, 1.36118808e-01,\n",
      "       1.61759564e-01, 1.14297004e-01, 3.00379992e-01, 9.50798698e-02,\n",
      "       1.02955096e-01, 1.29386944e-01, 4.18615264e-01, 1.15887048e-01,\n",
      "       1.51596045e-01, 5.75955883e-01, 1.31611653e+00, 1.70759557e+00,\n",
      "       5.24331074e-01, 7.27948221e-01, 1.01742684e-01, 1.17605485e-01,\n",
      "       2.42381894e-01, 1.67716986e-01, 2.08384251e-01, 4.47201516e-02,\n",
      "       2.24408646e-01, 1.27412377e-01, 4.05934651e-02, 1.70508872e-01,\n",
      "       6.79903419e-02, 4.92753820e-02, 5.34206319e-02, 6.50887907e-02,\n",
      "       8.38246260e-02, 8.57116907e-02, 5.60768773e-02, 1.17456757e-01,\n",
      "       6.01364639e-02, 6.19504696e-02, 5.88830593e-02, 8.00693166e-02,\n",
      "       2.44379995e-01, 8.96605905e-02, 1.18047360e-01, 2.41312333e-01,\n",
      "       1.38603868e-01, 2.15812312e+02, 1.16314687e+00, 6.59895930e-01,\n",
      "       3.99420030e-01, 2.49103940e-01, 1.59016870e-01, 1.77053657e-01,\n",
      "       8.30192219e-01, 6.87343352e-01, 7.05405663e-02, 5.11794286e-02,\n",
      "       2.52300311e-01, 1.92667881e-01, 1.23299111e-01, 4.83369523e-02,\n",
      "       1.80001297e-01, 2.44548059e-01, 9.41317375e-02, 1.15081100e-01,\n",
      "       1.13165792e-01, 1.25050597e-01, 2.57061313e-01, 1.49119633e-01,\n",
      "       5.43898328e-01, 1.72948052e-01, 5.82210516e-02, 3.39313570e-01,\n",
      "       4.03621915e-01, 1.37607939e-01, 1.06453813e-01, 7.13465281e-01,\n",
      "       1.11950783e+00, 5.54021427e-02, 1.74252676e-01, 1.37859432e-01,\n",
      "       2.58973659e-01, 1.42390870e-01, 3.02838418e+00]), 'mean_score_time': array([0.10851002, 0.11708689, 0.10392189, 0.09035902, 0.12207389,\n",
      "       0.12666211, 0.113097  , 0.17393594, 0.12965322, 0.12965155,\n",
      "       0.09873528, 0.12606182, 0.10950718, 0.12905469, 0.12027907,\n",
      "       0.12785954, 0.09594345, 0.1260633 , 0.08896194, 0.10511827,\n",
      "       0.1051188 , 0.10462241, 0.15538664, 0.11928153, 0.10731292,\n",
      "       0.11588979, 0.0965414 , 0.11110272, 0.10950704, 0.11628919,\n",
      "       0.09634213, 0.09674101, 0.12945461, 0.09694076, 0.08976049,\n",
      "       0.13484001, 0.11130209, 0.09354954, 0.09195418, 0.12007942,\n",
      "       0.09115644, 0.11708722, 0.11489258, 0.10803885, 0.09833717,\n",
      "       0.0897604 , 0.1140933 , 0.12985287, 0.12080412, 0.0857707 ,\n",
      "       0.12120204, 0.11195016, 0.09534559, 0.1035233 , 0.12327061,\n",
      "       0.11569481, 0.11210127, 0.10552044, 0.16316361, 0.12566447,\n",
      "       0.16595573, 0.27885385, 0.19196177, 0.15753298, 0.14639153,\n",
      "       0.15477204, 0.1144093 , 0.12765884, 0.11549129, 0.12247229,\n",
      "       0.11628895, 0.1525928 , 0.14740548, 0.15019913, 0.14441352,\n",
      "       0.11070409, 0.12307329, 0.12865663, 0.11429343, 0.09574418,\n",
      "       0.11748667, 0.11130204, 0.08656812, 0.09733982, 0.10831108,\n",
      "       0.10511866, 0.1130971 , 0.1017283 , 0.11050396, 0.10312438,\n",
      "       0.11010518, 0.08836298, 0.10591669, 0.09973321, 0.08577123,\n",
      "       0.09973335, 0.10910778, 0.08756561, 0.11329718, 0.09714026,\n",
      "       0.10312443, 0.10671415, 0.09694028, 0.10751257, 0.10910902,\n",
      "       0.0997333 , 0.09335055, 0.0939486 , 0.08317804, 0.10112953,\n",
      "       0.10172839, 0.09853683, 0.08058496, 0.10771194, 0.09813757,\n",
      "       0.12785802, 0.11529202, 0.11210012, 0.10950761, 0.10791159,\n",
      "       0.1083106 , 0.09753952, 0.11888199, 0.10073075, 0.09534574,\n",
      "       0.12127547, 0.09813762, 0.09793797, 0.10751262, 0.09574366,\n",
      "       0.10252576, 0.09514518, 0.09494629, 0.15806732, 0.13683419,\n",
      "       0.11090317, 0.08716702, 0.12386847, 0.09454713, 0.09474645,\n",
      "       0.10312362, 0.09035845, 0.08477359, 0.10033188, 0.10172534,\n",
      "       0.09973383, 0.10651526, 0.0853724 , 0.10731421, 0.10192766,\n",
      "       0.08377624, 0.09275208, 0.09215355, 0.0809834 , 0.08417506,\n",
      "       0.1047205 , 0.09873695, 0.10890851, 0.11828289, 0.12845416,\n",
      "       0.11967912, 0.08936119, 0.09674158, 0.08816471, 0.10691381,\n",
      "       0.07639608, 0.09953413, 0.08916168, 0.09893608, 0.1119916 ,\n",
      "       0.08836412]), 'std_score_time': array([0.0288679 , 0.0286604 , 0.01065606, 0.01509364, 0.02960328,\n",
      "       0.02536453, 0.00886719, 0.02433743, 0.04019662, 0.03389175,\n",
      "       0.01208424, 0.02299008, 0.02843641, 0.03378968, 0.04489022,\n",
      "       0.02202171, 0.00744712, 0.02584315, 0.00558519, 0.01974232,\n",
      "       0.01010378, 0.01475606, 0.07471954, 0.00499079, 0.01685038,\n",
      "       0.02138435, 0.00888503, 0.0196715 , 0.01471771, 0.03240704,\n",
      "       0.01230596, 0.0201354 , 0.03044919, 0.01172312, 0.01083374,\n",
      "       0.04015925, 0.02792963, 0.01172361, 0.01175705, 0.03567934,\n",
      "       0.01296659, 0.02458088, 0.04888074, 0.03161493, 0.01104479,\n",
      "       0.0087632 , 0.04205936, 0.03716419, 0.03130872, 0.0106115 ,\n",
      "       0.04074736, 0.03191645, 0.01026084, 0.02638211, 0.05051884,\n",
      "       0.01973637, 0.03421762, 0.01213815, 0.03864111, 0.00950317,\n",
      "       0.04033669, 0.07221807, 0.08792092, 0.06207463, 0.0187122 ,\n",
      "       0.04007543, 0.01326962, 0.03877038, 0.02636653, 0.02385516,\n",
      "       0.02156313, 0.06378605, 0.02470051, 0.03733123, 0.0500075 ,\n",
      "       0.02803312, 0.00823734, 0.04454446, 0.01856884, 0.0104223 ,\n",
      "       0.00895136, 0.03485088, 0.00324035, 0.01204402, 0.0270758 ,\n",
      "       0.01177723, 0.01772458, 0.02185976, 0.0262088 , 0.016077  ,\n",
      "       0.02479007, 0.01093576, 0.01104131, 0.01196838, 0.01057392,\n",
      "       0.01780706, 0.0326932 , 0.00967724, 0.0205807 , 0.01806916,\n",
      "       0.02119053, 0.02085413, 0.00486161, 0.01861983, 0.01467964,\n",
      "       0.01672409, 0.01477413, 0.00904006, 0.01463909, 0.02077295,\n",
      "       0.01364567, 0.01349043, 0.00840152, 0.00772518, 0.01680269,\n",
      "       0.02140356, 0.01795846, 0.02065745, 0.01241538, 0.0132216 ,\n",
      "       0.01301229, 0.00638267, 0.02517837, 0.0034545 , 0.01281242,\n",
      "       0.01891916, 0.02039625, 0.01478531, 0.01837266, 0.01046069,\n",
      "       0.0114307 , 0.00593738, 0.01420811, 0.06831836, 0.03738848,\n",
      "       0.03392963, 0.01093586, 0.01666895, 0.01056201, 0.01667667,\n",
      "       0.01496163, 0.01660035, 0.00574676, 0.01118792, 0.0221812 ,\n",
      "       0.01660535, 0.01441692, 0.00726316, 0.02747034, 0.01812161,\n",
      "       0.00682258, 0.01878604, 0.01118784, 0.00861145, 0.01215891,\n",
      "       0.01619297, 0.01943147, 0.04216877, 0.04500219, 0.05321099,\n",
      "       0.0426308 , 0.01052821, 0.01904867, 0.01709576, 0.01758797,\n",
      "       0.00819071, 0.0097597 , 0.00906617, 0.03024035, 0.03625951,\n",
      "       0.01898237]), 'param_max_depth': masked_array(data=[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "                   25, 25, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
      "                   30, 30, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_features': masked_array(data=[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6,\n",
      "                   7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 12,\n",
      "                   12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16,\n",
      "                   17, 17, 17, 18, 18, 18, 19, 19, 19, 1, 1, 1, 2, 2, 2,\n",
      "                   3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8,\n",
      "                   9, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13,\n",
      "                   13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 18,\n",
      "                   18, 18, 19, 19, 19, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4,\n",
      "                   5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10,\n",
      "                   10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15,\n",
      "                   15, 15, 16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[200, 210, 220, 200, 210, 220, 200, 210, 220, 200, 210,\n",
      "                   220, 200, 210, 220, 200, 210, 220, 200, 210, 220, 200,\n",
      "                   210, 220, 200, 210, 220, 200, 210, 220, 200, 210, 220,\n",
      "                   200, 210, 220, 200, 210, 220, 200, 210, 220, 200, 210,\n",
      "                   220, 200, 210, 220, 200, 210, 220, 200, 210, 220, 200,\n",
      "                   210, 220, 200, 210, 220, 200, 210, 220, 200, 210, 220,\n",
      "                   200, 210, 220, 200, 210, 220, 200, 210, 220, 200, 210,\n",
      "                   220, 200, 210, 220, 200, 210, 220, 200, 210, 220, 200,\n",
      "                   210, 220, 200, 210, 220, 200, 210, 220, 200, 210, 220,\n",
      "                   200, 210, 220, 200, 210, 220, 200, 210, 220, 200, 210,\n",
      "                   220, 200, 210, 220, 200, 210, 220, 200, 210, 220, 200,\n",
      "                   210, 220, 200, 210, 220, 200, 210, 220, 200, 210, 220,\n",
      "                   200, 210, 220, 200, 210, 220, 200, 210, 220, 200, 210,\n",
      "                   220, 200, 210, 220, 200, 210, 220, 200, 210, 220, 200,\n",
      "                   210, 220, 200, 210, 220, 200, 210, 220, 200, 210, 220,\n",
      "                   200, 210, 220, 200, 210, 220],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 20, 'max_features': 1, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 1, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 1, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 2, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 2, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 3, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 3, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 3, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 4, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 4, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 4, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 5, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 5, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 6, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 6, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 6, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 7, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 7, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 7, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 8, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 8, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 8, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 9, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 9, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 9, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 10, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 10, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 11, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 11, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 11, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 12, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 12, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 12, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 13, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 13, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 13, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 14, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 14, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 14, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 15, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 15, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 15, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 16, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 16, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 16, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 17, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 17, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 17, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 18, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 18, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 18, 'n_estimators': 220}, {'max_depth': 20, 'max_features': 19, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 19, 'n_estimators': 210}, {'max_depth': 20, 'max_features': 19, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 1, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 1, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 1, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 2, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 2, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 2, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 3, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 3, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 3, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 4, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 4, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 4, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 5, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 5, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 5, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 6, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 6, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 6, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 7, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 7, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 7, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 8, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 8, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 8, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 9, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 9, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 9, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 10, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 10, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 10, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 11, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 11, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 11, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 12, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 12, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 12, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 13, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 13, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 13, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 14, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 14, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 14, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 15, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 15, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 15, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 16, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 16, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 16, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 17, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 17, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 17, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 18, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 18, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 18, 'n_estimators': 220}, {'max_depth': 25, 'max_features': 19, 'n_estimators': 200}, {'max_depth': 25, 'max_features': 19, 'n_estimators': 210}, {'max_depth': 25, 'max_features': 19, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 1, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 1, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 1, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 2, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 2, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 2, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 3, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 3, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 3, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 4, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 4, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 4, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 5, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 5, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 5, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 6, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 6, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 6, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 7, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 7, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 7, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 8, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 8, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 8, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 9, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 9, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 9, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 10, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 10, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 10, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 11, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 11, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 11, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 12, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 12, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 12, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 13, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 13, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 13, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 14, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 14, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 14, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 15, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 15, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 15, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 16, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 16, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 16, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 17, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 17, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 17, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 18, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 18, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 18, 'n_estimators': 220}, {'max_depth': 30, 'max_features': 19, 'n_estimators': 200}, {'max_depth': 30, 'max_features': 19, 'n_estimators': 210}, {'max_depth': 30, 'max_features': 19, 'n_estimators': 220}], 'split0_test_score': array([0.84842707, 0.84556721, 0.84175405, 0.87225929, 0.86844614,\n",
      "       0.87225929, 0.88274547, 0.88465205, 0.88465205, 0.89323165,\n",
      "       0.8884652 , 0.88083889, 0.89513823, 0.89227836, 0.89609152,\n",
      "       0.90085796, 0.89990467, 0.89895138, 0.89609152, 0.90181125,\n",
      "       0.90371783, 0.90943756, 0.90181125, 0.9056244 , 0.91229743,\n",
      "       0.90943756, 0.9056244 , 0.9056244 , 0.90848427, 0.90657769,\n",
      "       0.90181125, 0.90467112, 0.90181125, 0.9056244 , 0.91039085,\n",
      "       0.90943756, 0.91039085, 0.90657769, 0.90467112, 0.90657769,\n",
      "       0.90657769, 0.90943756, 0.90753098, 0.90753098, 0.90848427,\n",
      "       0.90943756, 0.90467112, 0.90753098, 0.90371783, 0.91039085,\n",
      "       0.9056244 , 0.90943756, 0.90657769, 0.9056244 , 0.91134414,\n",
      "       0.90848427, 0.90753098, 0.85033365, 0.84938036, 0.84556721,\n",
      "       0.87511916, 0.87225929, 0.87607245, 0.88465205, 0.88560534,\n",
      "       0.88083889, 0.89323165, 0.88560534, 0.89418494, 0.89323165,\n",
      "       0.89227836, 0.89609152, 0.89513823, 0.89418494, 0.89799809,\n",
      "       0.90467112, 0.90085796, 0.90181125, 0.90753098, 0.91039085,\n",
      "       0.90181125, 0.90085796, 0.90467112, 0.90276454, 0.90943756,\n",
      "       0.90848427, 0.90753098, 0.90371783, 0.90276454, 0.90753098,\n",
      "       0.90753098, 0.91134414, 0.90657769, 0.90943756, 0.90753098,\n",
      "       0.90657769, 0.91134414, 0.90657769, 0.90181125, 0.90467112,\n",
      "       0.90753098, 0.90657769, 0.9056244 , 0.91134414, 0.90753098,\n",
      "       0.90848427, 0.90943756, 0.90753098, 0.90753098, 0.90943756,\n",
      "       0.9056244 , 0.91229743, 0.91229743, 0.91039085, 0.84842707,\n",
      "       0.84080076, 0.8379409 , 0.87607245, 0.87130601, 0.86749285,\n",
      "       0.88083889, 0.88274547, 0.88083889, 0.89227836, 0.89323165,\n",
      "       0.8884652 , 0.89132507, 0.90467112, 0.89513823, 0.89895138,\n",
      "       0.89799809, 0.89418494, 0.89990467, 0.90181125, 0.90181125,\n",
      "       0.90371783, 0.89799809, 0.90276454, 0.90943756, 0.90467112,\n",
      "       0.9056244 , 0.9056244 , 0.90753098, 0.9056244 , 0.90943756,\n",
      "       0.90753098, 0.9056244 , 0.90753098, 0.90467112, 0.90467112,\n",
      "       0.90467112, 0.90181125, 0.90467112, 0.90848427, 0.90943756,\n",
      "       0.90943756, 0.91039085, 0.90943756, 0.90276454, 0.90371783,\n",
      "       0.91039085, 0.91039085, 0.9056244 , 0.90657769, 0.914204  ,\n",
      "       0.90371783, 0.90943756, 0.91134414, 0.9056244 , 0.90753098,\n",
      "       0.90753098]), 'split1_test_score': array([0.85224023, 0.84842707, 0.84175405, 0.86653956, 0.87035272,\n",
      "       0.87035272, 0.87511916, 0.88083889, 0.88274547, 0.88655863,\n",
      "       0.88655863, 0.88179218, 0.88274547, 0.88560534, 0.88941849,\n",
      "       0.89323165, 0.88655863, 0.8884652 , 0.89418494, 0.89418494,\n",
      "       0.89418494, 0.8970448 , 0.90085796, 0.89418494, 0.89513823,\n",
      "       0.89799809, 0.90085796, 0.89895138, 0.89895138, 0.89990467,\n",
      "       0.8970448 , 0.89799809, 0.90181125, 0.89895138, 0.89895138,\n",
      "       0.8970448 , 0.89990467, 0.90276454, 0.90848427, 0.90085796,\n",
      "       0.90181125, 0.90181125, 0.90276454, 0.90181125, 0.90467112,\n",
      "       0.90467112, 0.90181125, 0.9056244 , 0.90276454, 0.90276454,\n",
      "       0.90276454, 0.90467112, 0.9056244 , 0.90276454, 0.90181125,\n",
      "       0.90276454, 0.90085796, 0.84747378, 0.84556721, 0.84461392,\n",
      "       0.87607245, 0.86844614, 0.87130601, 0.88274547, 0.87893232,\n",
      "       0.88179218, 0.88560534, 0.88655863, 0.88560534, 0.88655863,\n",
      "       0.88941849, 0.88274547, 0.89227836, 0.89513823, 0.89323165,\n",
      "       0.89323165, 0.89513823, 0.89227836, 0.89799809, 0.89037178,\n",
      "       0.8970448 , 0.89799809, 0.89609152, 0.89418494, 0.89990467,\n",
      "       0.89799809, 0.89513823, 0.90371783, 0.89513823, 0.90085796,\n",
      "       0.89990467, 0.90276454, 0.90276454, 0.90085796, 0.89799809,\n",
      "       0.90276454, 0.90181125, 0.8970448 , 0.90467112, 0.90181125,\n",
      "       0.90371783, 0.90753098, 0.9056244 , 0.90371783, 0.9056244 ,\n",
      "       0.89990467, 0.89990467, 0.90371783, 0.90276454, 0.90085796,\n",
      "       0.90371783, 0.90085796, 0.90276454, 0.90467112, 0.85128694,\n",
      "       0.8551001 , 0.85128694, 0.86653956, 0.86463298, 0.87130601,\n",
      "       0.87321258, 0.87607245, 0.87607245, 0.88274547, 0.89037178,\n",
      "       0.88274547, 0.8884652 , 0.88751192, 0.89037178, 0.89037178,\n",
      "       0.8884652 , 0.8884652 , 0.89227836, 0.8970448 , 0.89799809,\n",
      "       0.89513823, 0.8970448 , 0.89323165, 0.90085796, 0.8970448 ,\n",
      "       0.90467112, 0.89799809, 0.89513823, 0.89895138, 0.90276454,\n",
      "       0.8970448 , 0.90276454, 0.90657769, 0.8970448 , 0.8970448 ,\n",
      "       0.90276454, 0.8970448 , 0.8970448 , 0.90085796, 0.90085796,\n",
      "       0.90371783, 0.90657769, 0.89895138, 0.90657769, 0.89990467,\n",
      "       0.90085796, 0.90467112, 0.90085796, 0.90371783, 0.90753098,\n",
      "       0.90657769, 0.90371783, 0.89990467, 0.90276454, 0.9056244 ,\n",
      "       0.90467112]), 'split2_test_score': array([0.8293613 , 0.83889418, 0.83984747, 0.85414681, 0.85700667,\n",
      "       0.85986654, 0.86749285, 0.86272641, 0.86177312, 0.87893232,\n",
      "       0.87130601, 0.87321258, 0.87988561, 0.87988561, 0.87511916,\n",
      "       0.88369876, 0.87988561, 0.88179218, 0.88274547, 0.88655863,\n",
      "       0.88655863, 0.8884652 , 0.88655863, 0.88369876, 0.88560534,\n",
      "       0.89132507, 0.89323165, 0.8884652 , 0.88941849, 0.8884652 ,\n",
      "       0.8884652 , 0.89132507, 0.88941849, 0.8884652 , 0.8884652 ,\n",
      "       0.89132507, 0.89037178, 0.89037178, 0.88655863, 0.88941849,\n",
      "       0.8884652 , 0.89227836, 0.88751192, 0.89609152, 0.8884652 ,\n",
      "       0.89132507, 0.89513823, 0.8884652 , 0.8884652 , 0.89609152,\n",
      "       0.88751192, 0.89227836, 0.8884652 , 0.89037178, 0.89227836,\n",
      "       0.8884652 , 0.88655863, 0.84366063, 0.83889418, 0.84080076,\n",
      "       0.85128694, 0.85891325, 0.85795996, 0.87130601, 0.86939943,\n",
      "       0.86463298, 0.86939943, 0.87702574, 0.87416587, 0.87893232,\n",
      "       0.88465205, 0.87797903, 0.88369876, 0.88941849, 0.88179218,\n",
      "       0.88560534, 0.88751192, 0.88751192, 0.89323165, 0.88941849,\n",
      "       0.88751192, 0.89132507, 0.8884652 , 0.88655863, 0.88941849,\n",
      "       0.89037178, 0.88941849, 0.89037178, 0.88655863, 0.8884652 ,\n",
      "       0.88751192, 0.89323165, 0.88560534, 0.8884652 , 0.89227836,\n",
      "       0.89037178, 0.8884652 , 0.8884652 , 0.88560534, 0.89609152,\n",
      "       0.8884652 , 0.89037178, 0.88655863, 0.89132507, 0.89037178,\n",
      "       0.88941849, 0.89132507, 0.88751192, 0.89323165, 0.88751192,\n",
      "       0.89418494, 0.88655863, 0.89418494, 0.89132507, 0.83889418,\n",
      "       0.8465205 , 0.8465205 , 0.85319352, 0.85986654, 0.8551001 ,\n",
      "       0.86272641, 0.86844614, 0.87702574, 0.87511916, 0.87702574,\n",
      "       0.87225929, 0.88465205, 0.8884652 , 0.88274547, 0.88751192,\n",
      "       0.88083889, 0.88655863, 0.88369876, 0.8884652 , 0.88751192,\n",
      "       0.88941849, 0.88751192, 0.8884652 , 0.88560534, 0.88941849,\n",
      "       0.88751192, 0.8884652 , 0.89037178, 0.88560534, 0.88751192,\n",
      "       0.89037178, 0.89132507, 0.89037178, 0.89037178, 0.88655863,\n",
      "       0.89132507, 0.8884652 , 0.88560534, 0.88941849, 0.88941849,\n",
      "       0.88941849, 0.89132507, 0.88751192, 0.89132507, 0.89227836,\n",
      "       0.89132507, 0.89037178, 0.89323165, 0.88751192, 0.88560534,\n",
      "       0.89418494, 0.89132507, 0.89227836, 0.89323165, 0.89132507,\n",
      "       0.89323165]), 'split3_test_score': array([0.85019084, 0.85973282, 0.85019084, 0.87977099, 0.88358779,\n",
      "       0.88645038, 0.88740458, 0.88645038, 0.88931298, 0.89599237,\n",
      "       0.89503817, 0.89217557, 0.89599237, 0.89694656, 0.89408397,\n",
      "       0.90267176, 0.89694656, 0.89694656, 0.90648855, 0.89790076,\n",
      "       0.90458015, 0.90267176, 0.89980916, 0.90267176, 0.90648855,\n",
      "       0.89980916, 0.91030534, 0.90839695, 0.90839695, 0.90744275,\n",
      "       0.90839695, 0.90744275, 0.90648855, 0.90744275, 0.90458015,\n",
      "       0.90744275, 0.91221374, 0.90553435, 0.91030534, 0.90935115,\n",
      "       0.91125954, 0.91221374, 0.90648855, 0.90648855, 0.90648855,\n",
      "       0.90744275, 0.90648855, 0.91125954, 0.90839695, 0.90076336,\n",
      "       0.90744275, 0.90935115, 0.90839695, 0.90839695, 0.91030534,\n",
      "       0.90839695, 0.90458015, 0.85687023, 0.85114504, 0.85019084,\n",
      "       0.88167939, 0.8778626 , 0.88549618, 0.88740458, 0.89026718,\n",
      "       0.88931298, 0.89599237, 0.88931298, 0.89217557, 0.89790076,\n",
      "       0.89599237, 0.89694656, 0.90171756, 0.90458015, 0.89980916,\n",
      "       0.89885496, 0.89503817, 0.90362595, 0.90267176, 0.90839695,\n",
      "       0.90171756, 0.90458015, 0.90839695, 0.90171756, 0.90839695,\n",
      "       0.90458015, 0.90744275, 0.90648855, 0.90171756, 0.91125954,\n",
      "       0.90171756, 0.90648855, 0.90648855, 0.91030534, 0.90744275,\n",
      "       0.90744275, 0.90553435, 0.90744275, 0.90935115, 0.90458015,\n",
      "       0.91030534, 0.91030534, 0.90648855, 0.91125954, 0.90553435,\n",
      "       0.90935115, 0.91125954, 0.90458015, 0.90553435, 0.90744275,\n",
      "       0.91125954, 0.90648855, 0.90267176, 0.90839695, 0.84923664,\n",
      "       0.85114504, 0.85687023, 0.88358779, 0.88740458, 0.88358779,\n",
      "       0.89217557, 0.89217557, 0.88740458, 0.89503817, 0.89217557,\n",
      "       0.89790076, 0.89503817, 0.90458015, 0.90076336, 0.90076336,\n",
      "       0.89980916, 0.89694656, 0.89312977, 0.89885496, 0.90362595,\n",
      "       0.89503817, 0.90362595, 0.90171756, 0.90744275, 0.90171756,\n",
      "       0.90458015, 0.90076336, 0.90935115, 0.90935115, 0.90744275,\n",
      "       0.90744275, 0.90362595, 0.90744275, 0.90839695, 0.90553435,\n",
      "       0.91125954, 0.91030534, 0.90171756, 0.90458015, 0.90744275,\n",
      "       0.90458015, 0.90935115, 0.90839695, 0.90744275, 0.90553435,\n",
      "       0.90935115, 0.91221374, 0.90839695, 0.90839695, 0.91030534,\n",
      "       0.91030534, 0.90935115, 0.90744275, 0.91125954, 0.91412214,\n",
      "       0.90839695]), 'split4_test_score': array([0.83874046, 0.84637405, 0.84351145, 0.87022901, 0.87881679,\n",
      "       0.87118321, 0.88072519, 0.88167939, 0.88167939, 0.88740458,\n",
      "       0.89217557, 0.89217557, 0.89980916, 0.89503817, 0.90076336,\n",
      "       0.90267176, 0.89694656, 0.90362595, 0.91125954, 0.90267176,\n",
      "       0.90553435, 0.90839695, 0.91030534, 0.90839695, 0.91221374,\n",
      "       0.90362595, 0.91507634, 0.90553435, 0.91125954, 0.91221374,\n",
      "       0.90935115, 0.91030534, 0.90839695, 0.91316794, 0.91221374,\n",
      "       0.91221374, 0.91316794, 0.91125954, 0.91221374, 0.91603053,\n",
      "       0.91698473, 0.90935115, 0.91412214, 0.90935115, 0.91316794,\n",
      "       0.91603053, 0.91125954, 0.91316794, 0.91030534, 0.91603053,\n",
      "       0.91221374, 0.90839695, 0.91412214, 0.91316794, 0.91030534,\n",
      "       0.90935115, 0.90839695, 0.84732824, 0.84064885, 0.84541985,\n",
      "       0.8721374 , 0.86832061, 0.87022901, 0.87881679, 0.88740458,\n",
      "       0.88549618, 0.89026718, 0.88835878, 0.89503817, 0.89408397,\n",
      "       0.90076336, 0.89885496, 0.89790076, 0.90458015, 0.90267176,\n",
      "       0.90458015, 0.90171756, 0.90553435, 0.91030534, 0.91030534,\n",
      "       0.90935115, 0.91507634, 0.91603053, 0.91316794, 0.91030534,\n",
      "       0.90935115, 0.91125954, 0.90839695, 0.90744275, 0.91221374,\n",
      "       0.91125954, 0.91412214, 0.91507634, 0.91030534, 0.91221374,\n",
      "       0.91507634, 0.91030534, 0.91221374, 0.91221374, 0.91507634,\n",
      "       0.91316794, 0.91030534, 0.91030534, 0.91125954, 0.91316794,\n",
      "       0.91221374, 0.90839695, 0.91603053, 0.90839695, 0.91030534,\n",
      "       0.90935115, 0.90744275, 0.90935115, 0.91030534, 0.84064885,\n",
      "       0.83778626, 0.84732824, 0.86927481, 0.8769084 , 0.86736641,\n",
      "       0.88454198, 0.88645038, 0.89217557, 0.89503817, 0.89312977,\n",
      "       0.89122137, 0.89599237, 0.89885496, 0.89694656, 0.90362595,\n",
      "       0.90839695, 0.90076336, 0.90839695, 0.90648855, 0.90362595,\n",
      "       0.90839695, 0.91316794, 0.90935115, 0.91316794, 0.90744275,\n",
      "       0.91221374, 0.91221374, 0.90744275, 0.91030534, 0.91221374,\n",
      "       0.91412214, 0.91603053, 0.91316794, 0.91125954, 0.91125954,\n",
      "       0.91125954, 0.90935115, 0.91412214, 0.91507634, 0.90744275,\n",
      "       0.91030534, 0.91603053, 0.91316794, 0.91030534, 0.90839695,\n",
      "       0.91316794, 0.91221374, 0.91316794, 0.91221374, 0.90553435,\n",
      "       0.90935115, 0.91412214, 0.90744275, 0.91125954, 0.90839695,\n",
      "       0.90839695]), 'mean_test_score': array([0.84379198, 0.84779907, 0.84341157, 0.86858913, 0.87164202,\n",
      "       0.87202243, 0.87869745, 0.87926942, 0.8800326 , 0.88842391,\n",
      "       0.88670872, 0.88403896, 0.89071417, 0.88995081, 0.8910953 ,\n",
      "       0.89662638, 0.89204841, 0.89395626, 0.898154  , 0.89662547,\n",
      "       0.89891518, 0.90120325, 0.89986847, 0.89891536, 0.90234866,\n",
      "       0.90043917, 0.90501914, 0.90139446, 0.90330213, 0.90292081,\n",
      "       0.90101387, 0.90234847, 0.9015853 , 0.90273034, 0.90292027,\n",
      "       0.90349278, 0.9052098 , 0.90330158, 0.90444662, 0.90444717,\n",
      "       0.90501968, 0.90501841, 0.90368362, 0.90425469, 0.90425542,\n",
      "       0.90578141, 0.90387374, 0.90520961, 0.90272997, 0.90520816,\n",
      "       0.90311147, 0.90482703, 0.90463728, 0.90406512, 0.90520889,\n",
      "       0.90349242, 0.90158493, 0.84913331, 0.84512713, 0.84531851,\n",
      "       0.87125907, 0.86916038, 0.87221272, 0.88098498, 0.88232177,\n",
      "       0.88041464, 0.88689919, 0.88537229, 0.88823398, 0.89014147,\n",
      "       0.89262093, 0.89052351, 0.89414673, 0.89758039, 0.89510057,\n",
      "       0.89738864, 0.89605277, 0.89815237, 0.90234756, 0.90177668,\n",
      "       0.89948733, 0.90196752, 0.90273106, 0.89967872, 0.9034926 ,\n",
      "       0.90215709, 0.902158  , 0.90253859, 0.89872434, 0.90406549,\n",
      "       0.90158493, 0.9055902 , 0.90330249, 0.90387428, 0.90349278,\n",
      "       0.90444662, 0.90349206, 0.90234884, 0.90273052, 0.90444607,\n",
      "       0.90463746, 0.90501823, 0.90292027, 0.90578122, 0.90444589,\n",
      "       0.90387446, 0.90406476, 0.90387428, 0.90349169, 0.90311111,\n",
      "       0.90482757, 0.90272906, 0.90425396, 0.90501787, 0.84569874,\n",
      "       0.84627053, 0.84798936, 0.86973362, 0.8720237 , 0.86897063,\n",
      "       0.87869909, 0.881178  , 0.88270345, 0.88804387, 0.8891869 ,\n",
      "       0.88651842, 0.89109457, 0.89681667, 0.89319308, 0.89624488,\n",
      "       0.89510166, 0.89338374, 0.8954817 , 0.89853295, 0.89891463,\n",
      "       0.89834193, 0.89986974, 0.89910602, 0.90330231, 0.90005894,\n",
      "       0.90292027, 0.90101296, 0.90196698, 0.90196752, 0.9038741 ,\n",
      "       0.90330249, 0.9038741 , 0.90501823, 0.90234884, 0.90101369,\n",
      "       0.90425596, 0.90139555, 0.90063219, 0.90368344, 0.9029199 ,\n",
      "       0.90349188, 0.90673506, 0.90349315, 0.90368308, 0.90196643,\n",
      "       0.90501859, 0.90597225, 0.90425578, 0.90368362, 0.904636  ,\n",
      "       0.90482739, 0.90559075, 0.90368253, 0.90482794, 0.90539991,\n",
      "       0.90444553]), 'std_test_score': array([0.00857397, 0.00676931, 0.00358235, 0.00841397, 0.00916786,\n",
      "       0.00847915, 0.00685069, 0.00851447, 0.00949679, 0.00591616,\n",
      "       0.00824157, 0.00727884, 0.00788554, 0.00633136, 0.00877969,\n",
      "       0.00734366, 0.00758652, 0.00781681, 0.00998649, 0.00587152,\n",
      "       0.00740311, 0.00776222, 0.00762676, 0.00897713, 0.01044764,\n",
      "       0.00600915, 0.00755934, 0.00717217, 0.00809712, 0.00822485,\n",
      "       0.00771853, 0.0068571 , 0.00661171, 0.00845341, 0.00859807,\n",
      "       0.00795773, 0.00880388, 0.00702162, 0.00928425, 0.00896109,\n",
      "       0.0096837 , 0.00724802, 0.00887695, 0.00478134, 0.00838817,\n",
      "       0.00814114, 0.00534015, 0.0087849 , 0.00766761, 0.0071109 ,\n",
      "       0.00838323, 0.00651095, 0.00860666, 0.00765841, 0.00732573,\n",
      "       0.00786949, 0.00796302, 0.00441052, 0.00476242, 0.00299059,\n",
      "       0.01045284, 0.00618952, 0.00893584, 0.00558823, 0.00745951,\n",
      "       0.00843968, 0.00940261, 0.00437206, 0.00777262, 0.00669001,\n",
      "       0.0055053 , 0.00847978, 0.00608349, 0.00603495, 0.00732796,\n",
      "       0.00725299, 0.00509886, 0.00700806, 0.00620189, 0.00973207,\n",
      "       0.00717002, 0.00786023, 0.00959521, 0.0089214 , 0.00795943,\n",
      "       0.0071253 , 0.00838102, 0.00633616, 0.00724097, 0.00876145,\n",
      "       0.00812212, 0.00731337, 0.00972605, 0.0084877 , 0.00726525,\n",
      "       0.00809246, 0.00825686, 0.00850924, 0.00929136, 0.00616136,\n",
      "       0.0086678 , 0.00747223, 0.00836182, 0.0078001 , 0.00756632,\n",
      "       0.00831291, 0.00747002, 0.0092671 , 0.00548356, 0.00847296,\n",
      "       0.0059492 , 0.00886443, 0.00627353, 0.00715342, 0.00495967,\n",
      "       0.00638257, 0.00621788, 0.01015979, 0.00962669, 0.0091243 ,\n",
      "       0.01005547, 0.00823855, 0.00618878, 0.00788533, 0.00616662,\n",
      "       0.0086374 , 0.00419555, 0.0075159 , 0.00620151, 0.00621257,\n",
      "       0.00953712, 0.00526438, 0.00825829, 0.00596182, 0.00606045,\n",
      "       0.00679426, 0.00842793, 0.00738786, 0.00970848, 0.00633795,\n",
      "       0.00820876, 0.00791607, 0.00770128, 0.00910196, 0.00874287,\n",
      "       0.00846698, 0.0078691 , 0.00768844, 0.00765449, 0.00852633,\n",
      "       0.00731717, 0.00811137, 0.00936104, 0.00854543, 0.00734754,\n",
      "       0.0074976 , 0.00829587, 0.00926296, 0.00663223, 0.00557241,\n",
      "       0.00798583, 0.00827652, 0.00680479, 0.00854259, 0.0099503 ,\n",
      "       0.00579705, 0.007858  , 0.00680156, 0.00666479, 0.0075862 ,\n",
      "       0.00577147]), 'rank_test_score': array([170, 165, 171, 162, 157, 156, 153, 151, 150, 137, 141, 144, 132,\n",
      "       135, 130, 117, 129, 125, 112, 118, 107,  94, 102, 106,  79,  99,\n",
      "        13,  93,  62,  66,  95,  80,  89,  73,  67,  52,   8,  63,  27,\n",
      "        26,  12,  15,  46,  35,  34,   3,  45,   9,  74,  11,  64,  22,\n",
      "        24,  38,  10,  55,  90, 163, 169, 168, 158, 160, 154, 148, 146,\n",
      "       149, 140, 143, 138, 134, 128, 133, 124, 114, 123, 115, 120, 113,\n",
      "        81,  88, 104,  84,  71, 103,  54,  83,  82,  76, 109,  37,  90,\n",
      "         6,  59,  41,  52,  28,  56,  77,  72,  29,  23,  16,  69,   4,\n",
      "        30,  40,  39,  41,  58,  65,  20,  75,  36,  18, 167, 166, 164,\n",
      "       159, 155, 161, 152, 147, 145, 139, 136, 142, 131, 116, 127, 119,\n",
      "       122, 126, 121, 110, 108, 111, 101, 105,  61, 100,  67,  97,  86,\n",
      "        84,  43,  59,  44,  17,  77,  96,  32,  92,  98,  48,  70,  57,\n",
      "         1,  51,  49,  87,  14,   2,  33,  46,  25,  21,   5,  50,  19,\n",
      "         7,  31])}\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.82      0.76      0.79       422\n",
      "     CONFIRMED       0.79      0.82      0.81       450\n",
      "FALSE POSITIVE       0.98      1.00      0.99       876\n",
      "\n",
      "      accuracy                           0.89      1748\n",
      "     macro avg       0.87      0.86      0.86      1748\n",
      "  weighted avg       0.89      0.89      0.89      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check performance of model with classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)\n",
    "pd.crosstab(y_test, predictions, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "\n",
    "filename = 'your_name.sav'\n",
    "joblib.dump(your_model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
